{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve YM2413-MDB (v1.0.2) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Define the directory containing MIDI files\n",
    "midi_files_directory = pathlib.Path('../music_dataset/YM2413-MDB-v1.0.2/midi/adjust_tempo_remove_delayed_inst')\n",
    "\n",
    "# Get a list of MIDI files\n",
    "midi_file_paths = list(midi_files_directory.glob('*.mid*'))\n",
    "# print('Number of MIDI files:', len(midi_file_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# import pretty_midi\n",
    "\n",
    "# # Set maximum tick value for pretty_midi\n",
    "# pretty_midi.pretty_midi.MAX_TICK = 1e16\n",
    "\n",
    "# # Initialize list to store inspection results\n",
    "# inspection_results = []\n",
    "\n",
    "# for midi_file_path in midi_file_paths:\n",
    "#     # Convert Path object to string\n",
    "#     midi_file_path_str = str(midi_file_path)\n",
    "    \n",
    "#     # Process MIDI file\n",
    "#     midi_data = pretty_midi.PrettyMIDI(midi_file_path_str)\n",
    "#     num_instruments = len(midi_data.instruments)\n",
    "#     instrument_names = [pretty_midi.program_to_instrument_name(inst.program) for inst in midi_data.instruments]\n",
    "\n",
    "#     # Store inspection results\n",
    "#     inspection_results.append({\n",
    "#         \"Filename\": os.path.basename(midi_file_path_str),\n",
    "#         \"Number of Instruments\": num_instruments,\n",
    "#         \"Instrument Names\": instrument_names\n",
    "#     })\n",
    "\n",
    "# # Write inspection results to CSV file\n",
    "# csv_output_file = '../ym2413_jupyter_xt/inspect.csv'\n",
    "# csv_columns = [\"Filename\", \"Number of Instruments\", \"Instrument Names\"]\n",
    "\n",
    "# with open(csv_output_file, \"w\", newline=\"\") as csvfile:\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "#     writer.writeheader()\n",
    "#     for result in inspection_results:\n",
    "#         writer.writerow(result)\n",
    "\n",
    "# print(\"Inspection results saved to\", csv_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert MIDI to Nintendo Entertainment System (NES) Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import pretty_midi\n",
    "import csv\n",
    "\n",
    "# Define the pitch ranges for NES instruments\n",
    "nes_instrument_name_to_min_pitch = {\n",
    "    'p1': 33,\n",
    "    'p2': 33,\n",
    "    'tr': 21\n",
    "}\n",
    "nes_instrument_name_to_max_pitch = {\n",
    "    'p1': 108,\n",
    "    'p2': 108,\n",
    "    'tr': 108\n",
    "}\n",
    "\n",
    "def is_instrument_monophonic(instrument):\n",
    "    notes = instrument.notes\n",
    "    last_note_start = -1\n",
    "    for note in notes:\n",
    "        assert note.start >= last_note_start\n",
    "        last_note_start = note.start\n",
    "\n",
    "    monophonic = True\n",
    "    for i in range(len(notes) - 1):\n",
    "        note0 = notes[i]\n",
    "        note1 = notes[i + 1]\n",
    "        if note0.end > note1.start:\n",
    "            monophonic = False\n",
    "            break\n",
    "    return monophonic\n",
    "\n",
    "def generate_nesmdb_midi_examples(\n",
    "    midi_filepath,\n",
    "    output_directory,\n",
    "    min_num_instruments=1,\n",
    "    min_length_seconds=5.,\n",
    "    max_length_seconds=600.,\n",
    "    filter_bad_times=True,\n",
    "    min_pitch=21,\n",
    "    max_pitch=108,\n",
    "    filter_duplicates=True,\n",
    "    include_drums=True,\n",
    "    max_examples=16,\n",
    "    max_duration_seconds=180.,\n",
    "    emotion_mapping=None):\n",
    "\n",
    "    midi_name = os.path.splitext(os.path.basename(midi_filepath))[0]\n",
    "\n",
    "    if min_num_instruments <= 0:\n",
    "        raise ValueError()\n",
    "\n",
    "    if os.path.getsize(midi_filepath) > (512 * 1024): # 512K\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_filepath)\n",
    "    except:\n",
    "        return\n",
    "\n",
    "    midi_length = midi_data.get_end_time()\n",
    "    if midi_length < min_length_seconds or midi_length > max_length_seconds:\n",
    "        return\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            if filter_bad_times:\n",
    "                if note.start < 0 or note.end < 0 or note.end < note.start:\n",
    "                    return\n",
    "            note.start = round(note.start * 44100.) / 44100.\n",
    "            note.end = round(note.end * 44100.) / 44100.\n",
    "\n",
    "    instruments = midi_data.instruments\n",
    "    drums = [i for i in instruments if i.is_drum]\n",
    "    instruments = [i for i in instruments if not i.is_drum]\n",
    "\n",
    "    instruments_in_range = []\n",
    "    for instrument in instruments:\n",
    "        pitches = [n.pitch for n in instrument.notes]\n",
    "        min_pitch_instrument = min(pitches)\n",
    "        max_pitch_instrument = max(pitches)\n",
    "        if max_pitch_instrument >= min_pitch and min_pitch_instrument <= max_pitch:\n",
    "            instruments_in_range.append(instrument)\n",
    "    instruments = instruments_in_range\n",
    "    if len(instruments) < min_num_instruments:\n",
    "        return\n",
    "\n",
    "    for instrument in instruments:\n",
    "        instrument.notes = sorted(instrument.notes, key=lambda x: x.start)\n",
    "    if include_drums:\n",
    "        for instrument in drums:\n",
    "            instrument.notes = sorted(instrument.notes, key=lambda x: x.start)\n",
    "\n",
    "    instruments = [i for i in instruments if is_instrument_monophonic(i)]\n",
    "    if len(instruments) < min_num_instruments:\n",
    "        return\n",
    "\n",
    "    if filter_duplicates:\n",
    "        unique_notes = set()\n",
    "        unique_instruments = []\n",
    "        for instrument in instruments:\n",
    "            pitches = ','.join(['{}:{:.1f}'.format(str(note.pitch), note.start) for note in instrument.notes])\n",
    "            if pitches not in unique_notes:\n",
    "                unique_instruments.append(instrument)\n",
    "                unique_notes.add(pitches)\n",
    "        instruments = unique_instruments\n",
    "        if len(instruments) < min_num_instruments:\n",
    "            return\n",
    "\n",
    "    num_instruments = len(instruments)\n",
    "    if num_instruments == 1:\n",
    "        instrument_permutations = [(0, -1, -1), (-1, 0, -1), (-1, -1, 0)]\n",
    "    elif num_instruments == 2:\n",
    "        instrument_permutations = [(-1, 0, 1), (-1, 1, 0), (0, -1, 1), (0, 1, -1), (1, -1, 0), (1, 0, -1)]\n",
    "    elif num_instruments > 32:\n",
    "        instrument_permutations = list(itertools.permutations(random.sample(range(num_instruments), 32), 3))\n",
    "    else:\n",
    "        instrument_permutations = list(itertools.permutations(range(num_instruments), 3))\n",
    "\n",
    "    if len(instrument_permutations) > max_examples:\n",
    "        instrument_permutations = random.sample(instrument_permutations, max_examples)\n",
    "\n",
    "    num_drums = len(drums) if include_drums else 0\n",
    "    instrument_permutations_plus_drums = []\n",
    "    for permutation in instrument_permutations:\n",
    "        selection = -1 if num_drums == 0 else random.choice(range(num_drums))\n",
    "        instrument_permutations_plus_drums.append(permutation + (selection,))\n",
    "    instrument_permutations = instrument_permutations_plus_drums\n",
    "\n",
    "    quarter_label = emotion_mapping.get(midi_name, 'Unknown')\n",
    "    emotion_mapping_dict = {\n",
    "        'Q1': 'happy',\n",
    "        'Q2': 'angry',\n",
    "        'Q3': 'sad',\n",
    "        'Q4': 'relaxed'\n",
    "    }\n",
    "    emotion_label = emotion_mapping_dict.get(quarter_label, 'Other')\n",
    "    output_subdir = f\"{quarter_label}_{emotion_label}\"\n",
    "    file_output_directory = os.path.join(output_directory, output_subdir)\n",
    "    os.makedirs(file_output_directory, exist_ok=True)\n",
    "\n",
    "    for i, permutation in enumerate(instrument_permutations):\n",
    "        lead1_program = pretty_midi.instrument_name_to_program('Lead 1 (square)')\n",
    "        lead2_program = pretty_midi.instrument_name_to_program('Lead 2 (sawtooth)')\n",
    "        bass_program = pretty_midi.instrument_name_to_program('Synth Bass 1')\n",
    "        drum_program = pretty_midi.instrument_name_to_program('Breath Noise')\n",
    "        lead1_instrument = pretty_midi.Instrument(program=lead1_program, name='p1', is_drum=False)\n",
    "        lead2_instrument = pretty_midi.Instrument(program=lead2_program, name='p2', is_drum=False)\n",
    "        bass_instrument = pretty_midi.Instrument(program=bass_program, name='tr', is_drum=False)\n",
    "        drum_instrument = pretty_midi.Instrument(program=drum_program, name='no', is_drum=True)\n",
    "\n",
    "        permutation_notes = []\n",
    "        for midi_instrument_id, nes_instrument_name in zip(permutation, ['p1', 'p2', 'tr', 'no']):\n",
    "            if midi_instrument_id < 0:\n",
    "                permutation_notes.append(None)\n",
    "            else:\n",
    "                if nes_instrument_name == 'no':\n",
    "                    midi_instrument = drums[midi_instrument_id]\n",
    "                    valid_notes = midi_instrument.notes\n",
    "                else:\n",
    "                    midi_instrument = instruments[midi_instrument_id]\n",
    "                    valid_notes = [n for n in midi_instrument.notes if n.pitch >= nes_instrument_name_to_min_pitch[nes_instrument_name] and n.pitch <= nes_instrument_name_to_max_pitch[nes_instrument_name]]\n",
    "                permutation_notes.append(valid_notes)\n",
    "        assert len(permutation_notes) == 4\n",
    "\n",
    "        start_time = None\n",
    "        end_time = None\n",
    "        for notes in permutation_notes:\n",
    "            if notes is None or len(notes) == 0:\n",
    "                continue\n",
    "            note_start = min([n.start for n in notes])\n",
    "            note_end = max([n.end for n in notes])\n",
    "            if start_time is None or note_start < start_time:\n",
    "                start_time = note_start\n",
    "            if end_time is None or note_end > end_time:\n",
    "                end_time = note_end\n",
    "        if start_time is None or end_time is None:\n",
    "            continue\n",
    "\n",
    "        if (end_time - start_time) > max_duration_seconds:\n",
    "            end_time = start_time + max_duration_seconds\n",
    "\n",
    "        for notes, instrument_name, instrument in zip(permutation_notes, ['p1', 'p2', 'tr', 'no'], [lead1_instrument, lead2_instrument, bass_instrument, drum_instrument]):\n",
    "            if notes is None:\n",
    "                continue\n",
    "\n",
    "            if instrument_name == 'no':\n",
    "                random_noise_mapping = [random.randint(1, 16) for _ in range(128)]\n",
    "\n",
    "            last_note_end = -1\n",
    "            for note in notes:\n",
    "                velocity = note.velocity\n",
    "                pitch = note.pitch\n",
    "                note_start = note.start\n",
    "                note_end = note.end\n",
    "\n",
    "                if instrument_name == 'no' and note_start < last_note_end:\n",
    "                    continue\n",
    "                last_note_end = note_end\n",
    "\n",
    "                assert note_start >= start_time\n",
    "                if note_end > end_time:\n",
    "                    continue\n",
    "                assert note_end <= end_time\n",
    "\n",
    "                velocity = 1 if instrument_name == 'tr' else int(round(1. + (14. * velocity / 127.)))\n",
    "                assert velocity > 0\n",
    "                if instrument_name == 'no':\n",
    "                    pitch = random_noise_mapping[pitch]\n",
    "                note_start = note_start - start_time\n",
    "                note_end = note_end - start_time\n",
    "                instrument.notes.append(\n",
    "                    pretty_midi.Note(\n",
    "                        velocity=velocity,\n",
    "                        pitch=pitch,\n",
    "                        start=note_start,\n",
    "                        end=note_end\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        midi_output = pretty_midi.PrettyMIDI()\n",
    "        for inst in [lead1_instrument, lead2_instrument, bass_instrument, drum_instrument]:\n",
    "            if len(inst.notes) > 0:\n",
    "                midi_output.instruments.append(inst)\n",
    "        end_instrument = pretty_midi.Instrument(program=0, name='end', is_drum=False)\n",
    "        end_instrument.notes.append(\n",
    "            pretty_midi.Note(\n",
    "                velocity=15,\n",
    "                pitch=108,\n",
    "                start=(end_time - start_time),\n",
    "                end=(end_time - start_time) + .1\n",
    "            )\n",
    "        )\n",
    "        midi_output.instruments.append(end_instrument)\n",
    "\n",
    "        output_midi_filepath = os.path.join(file_output_directory, f\"{midi_name}_{i}.mid\")\n",
    "        midi_output.write(output_midi_filepath)\n",
    "\n",
    "def load_emotion_mapping(csv_filepath):\n",
    "    emotion_mapping = {}\n",
    "    with open(csv_filepath, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            filename = os.path.splitext(os.path.basename(row[0]))[0]\n",
    "            emotion_mapping[filename] = row[3]\n",
    "    return emotion_mapping\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pretty_midi.pretty_midi.MAX_TICK = 1e16\n",
    "\n",
    "    emotion_mapping = load_emotion_mapping('../music_dataset/YM2413-MDB-v1.0.2/emotion_annotation/verified_annotation.csv')\n",
    "    midi_data_directory = '../music_dataset/YM2413-MDB-v1.0.2/midi/adjust_tempo_remove_delayed_inst'\n",
    "    output_directory = './1_output'\n",
    "\n",
    "    for midi_filename in os.listdir(midi_data_directory):\n",
    "        if midi_filename.endswith('.mid'):\n",
    "            generate_nesmdb_midi_examples(\n",
    "                os.path.join(midi_data_directory, midi_filename),\n",
    "                output_directory,\n",
    "                emotion_mapping=emotion_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Total Number of Files After MIDI-NES Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_files_directory = pathlib.Path('./1_output')\n",
    "# midi_file_paths = list(midi_files_directory.rglob('*.mid*'))\n",
    "# print('Number of files (after permutations):', len(midi_file_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect MIDI Files After MIDI-NES Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# import pretty_midi\n",
    "\n",
    "# pretty_midi.pretty_midi.MAX_TICK = 1e16\n",
    "\n",
    "# # Initialize list to store inspection results\n",
    "# inspection_results = []\n",
    "\n",
    "# for midi_file_path in midi_file_paths:\n",
    "#     # Convert Path object to string\n",
    "#     midi_file_path_str = str(midi_file_path)\n",
    "    \n",
    "#     # Process MIDI file\n",
    "#     midi_data = pretty_midi.PrettyMIDI(midi_file_path_str)\n",
    "#     num_instruments = len(midi_data.instruments)\n",
    "#     instrument_names = [pretty_midi.program_to_instrument_name(inst.program) for inst in midi_data.instruments]\n",
    "\n",
    "#     # Store inspection results\n",
    "#     inspection_results.append({\n",
    "#         \"Filename\": os.path.basename(midi_file_path_str),\n",
    "#         \"Number of Instruments\": num_instruments,\n",
    "#         \"Instrument Names\": instrument_names\n",
    "#     })\n",
    "\n",
    "# # Write inspection results to CSV file\n",
    "# csv_output_file = './converted_inspect.csv'\n",
    "# csv_columns = [\"Filename\", \"Number of Instruments\", \"Instrument Names\"]\n",
    "\n",
    "# with open(csv_output_file, \"w\", newline=\"\") as csvfile:\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "#     writer.writeheader()\n",
    "#     for result in inspection_results:\n",
    "#         writer.writerow(result)\n",
    "\n",
    "# print(\"Inspection results saved to\", csv_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Musical Information From Formatted MIDI Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Musical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "instrument_vocab = set()\n",
    "\n",
    "def round_features(features, precision=4):\n",
    "    # Round all float values in the feature dictionaries to a specified precision\n",
    "    rounded_features = []\n",
    "    for feature in features:\n",
    "        rounded_features.append({\n",
    "            'pitch': feature['pitch'],\n",
    "            'velocity': feature['velocity'],\n",
    "            'duration': round(feature['duration'], precision),\n",
    "            'tempo': round(feature.get('tempo', 0), precision)  # Use get to provide a default value\n",
    "        })\n",
    "    return rounded_features\n",
    "\n",
    "def extract_midi_features(midi_file, instrument_vocab, precision=4):\n",
    "    # print(f'Loading MIDI file: {midi_file}')\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    \n",
    "    instrument_features = {}\n",
    "    for instrument in midi_data.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "            # print(f'Processing instrument: {instrument_name}')\n",
    "            instrument_vocab.add(instrument_name)  # Update the set with new instrument\n",
    "            \n",
    "            notes_data = []\n",
    "            last_end_time = 0\n",
    "            for note in instrument.notes:\n",
    "                # Handle silence between notes\n",
    "                if note.start > last_end_time:\n",
    "                    silence_duration = note.start - last_end_time\n",
    "                    silence_features = {\n",
    "                        'pitch': 0,\n",
    "                        'velocity': 0,\n",
    "                        'duration': silence_duration,\n",
    "                        'tempo': 0\n",
    "                    }\n",
    "                    notes_data.append(silence_features)\n",
    "\n",
    "                note_features = {\n",
    "                    'pitch': note.pitch,\n",
    "                    'velocity': note.velocity,\n",
    "                    'duration': note.end - note.start,\n",
    "                    'tempo': 0  # Initialize tempo with 0\n",
    "                }\n",
    "                notes_data.append(note_features)\n",
    "                last_end_time = note.end\n",
    "\n",
    "            # Compute tempos for notes\n",
    "            tempo_changes = midi_data.get_tempo_changes()\n",
    "            tempos = np.interp([note.start for note in instrument.notes], tempo_changes[0], tempo_changes[1])\n",
    "            for note_data, tempo in zip([nd for nd in notes_data if nd['pitch'] != 0], tempos):\n",
    "                note_data['tempo'] = tempo\n",
    "            \n",
    "            instrument_features[instrument_name] = round_features(notes_data, precision)\n",
    "    return instrument_features, instrument_vocab\n",
    "\n",
    "def process_midi_dataset(dataset_path, output_path, process_path, precision=4):\n",
    "    instrument_vocab = set()\n",
    "\n",
    "    for mood_folder in os.listdir(dataset_path):\n",
    "        mood_path = os.path.join(dataset_path, mood_folder)\n",
    "        if os.path.isdir(mood_path):\n",
    "            mood_label = os.path.basename(mood_path)\n",
    "            mood_label_clean = re.sub(r'^Q\\d+_', '', mood_label)\n",
    "            print(f'Processing mood: {mood_label_clean}')\n",
    "            \n",
    "            for midi_file in os.listdir(mood_path):\n",
    "                if midi_file.endswith('.mid'):\n",
    "                    midi_path = os.path.join(mood_path, midi_file)\n",
    "                    # print(f'Processing file: {midi_path}')\n",
    "                    instrument_features, instrument_vocab = extract_midi_features(midi_path, instrument_vocab, precision)\n",
    "\n",
    "                    if not instrument_features or all(len(v) == 0 for v in instrument_features.values()):\n",
    "                        print(f\"No valid features found in {midi_file}, skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    track_id = os.path.splitext(midi_file)[0]\n",
    "                    features = {\n",
    "                        'track_id': track_id,\n",
    "                        'mood': mood_label_clean,\n",
    "                        'instruments': instrument_features\n",
    "                    }\n",
    "                    \n",
    "                    output_subpath = os.path.join(output_path, mood_label_clean)\n",
    "                    os.makedirs(output_subpath, exist_ok=True)\n",
    "                    json_file_name = f'{track_id}.json'\n",
    "                    output_file_path = os.path.join(output_subpath, json_file_name)\n",
    "                    \n",
    "                    with open(output_file_path, 'w') as json_file:\n",
    "                        json.dump(features, json_file, indent=4)\n",
    "                    \n",
    "                    # print(f'Saved features to: {output_file_path}')\n",
    "    \n",
    "    os.makedirs(process_path, exist_ok=True)\n",
    "\n",
    "    # Save the instrument vocabulary to a JSON file\n",
    "    instrument_dict = {instrument: idx for idx, instrument in enumerate(sorted(instrument_vocab))}\n",
    "    with open(os.path.join(process_path, 'instrument_vocab.json'), 'w') as vocab_file:\n",
    "        json.dump(instrument_dict, vocab_file, indent=4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_path = './1_output'\n",
    "    output_path = './2_output_features'\n",
    "    process_path = './3_processed_features'\n",
    "\n",
    "    process_midi_dataset(dataset_path, output_path, process_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Extracted Musical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_instrument_vocab(vocab_path):\n",
    "    \"\"\"Load the instrument vocabulary from a JSON file.\"\"\"\n",
    "    with open(vocab_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def load_instrument_specific_vocab(dataset_path):\n",
    "    instrument_event_vocab = defaultdict(lambda: {\"<PAD>\": 0})  # Nested dictionary for each instrument\n",
    "    instrument_event_id = defaultdict(lambda: 1)  # Separate ID counters for each instrument\n",
    "    for mood in os.listdir(dataset_path):\n",
    "        mood_path = os.path.join(dataset_path, mood)\n",
    "        if os.path.isdir(mood_path):\n",
    "            print(f'Processing mood: {mood}')\n",
    "            for json_file in os.listdir(mood_path):\n",
    "                if json_file.endswith('.json'):\n",
    "                    json_path = os.path.join(mood_path, json_file)\n",
    "                    with open(json_path, 'r') as file:\n",
    "                        data = json.load(file)\n",
    "                        instruments = data.get('instruments', {})\n",
    "                        for instrument, events in instruments.items():\n",
    "                            for event in events:\n",
    "                                event_key = tuple(sorted(event.items()))  # Create a hashable event key\n",
    "                                if event_key not in instrument_event_vocab[instrument]:\n",
    "                                    instrument_event_vocab[instrument][event_key] = instrument_event_id[instrument]\n",
    "                                    instrument_event_id[instrument] += 1\n",
    "    return instrument_event_vocab\n",
    "\n",
    "def save_vocab(vocab, output_folder):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Iterate over each instrument's vocabulary and save to separate files\n",
    "    for instrument, events in vocab.items():\n",
    "        vocab_dict = {str(key): value for key, value in events.items()}\n",
    "        output_path = os.path.join(output_folder, f\"{instrument}_vocab.json\")\n",
    "        with open(output_path, 'w') as file:\n",
    "            json.dump(vocab_dict, file, indent=4)\n",
    "        print(f'Vocabulary for {instrument} saved to {output_path}')\n",
    "\n",
    "def load_all_vocabs(vocab_folder):\n",
    "    \"\"\"Load all vocabularies from the specified folder into a dictionary.\"\"\"\n",
    "    vocabs = {}\n",
    "    for vocab_file in os.listdir(vocab_folder):\n",
    "        if vocab_file.endswith('_vocab.json'):\n",
    "            instrument = vocab_file.replace('_vocab.json', '')\n",
    "            with open(os.path.join(vocab_folder, vocab_file), 'r') as file:\n",
    "                vocabs[instrument] = json.load(file)\n",
    "    \n",
    "    # Convert keys from string to tuple, skip <PAD> token\n",
    "    processed_vocabs = {}\n",
    "    for instr, vocab in vocabs.items():\n",
    "        vocab_dict = {}\n",
    "        for key, value in vocab.items():\n",
    "            if key != \"<PAD>\":  # Skip the PAD token\n",
    "                try:\n",
    "                    # Try to convert the string representation of the tuple to an actual tuple\n",
    "                    tuple_key = tuple(eval(key))\n",
    "                    vocab_dict[tuple_key] = value\n",
    "                except SyntaxError:\n",
    "                    # If there is a syntax error in eval, log or ignore\n",
    "                    print(f\"Error evaluating key {key}: Skipping\")\n",
    "        processed_vocabs[instr] = vocab_dict\n",
    "    return processed_vocabs\n",
    "\n",
    "def transform_dataset(dataset_path, vocabs, instrument_vocab, output_folder):\n",
    "    num_instruments = len(instrument_vocab)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for mood in os.listdir(dataset_path):\n",
    "        mood_path = os.path.join(dataset_path, mood)\n",
    "        if os.path.isdir(mood_path):\n",
    "            output_mood_path = os.path.join(output_folder, mood)\n",
    "            os.makedirs(output_mood_path, exist_ok=True)\n",
    "            for json_file in os.listdir(mood_path):\n",
    "                if json_file.endswith('.json'):\n",
    "                    json_path = os.path.join(mood_path, json_file)\n",
    "                    with open(json_path, 'r') as file:\n",
    "                        data = json.load(file)\n",
    "                        transformed_instruments = {}\n",
    "                        instrument_vector = [0] * num_instruments\n",
    "                        for instrument, events in data['instruments'].items():\n",
    "                            if instrument in vocabs:  # Check if there's a vocab for this instrument\n",
    "                                vocab = vocabs[instrument]\n",
    "                                transformed_events = [vocab.get(tuple(sorted(event.items())), -1) for event in events]  # Get event ID or -1 if not found\n",
    "                                transformed_instruments[instrument] = transformed_events\n",
    "                        transformed_data = {\n",
    "                            'mood': data['mood'],\n",
    "                            'instrument_vector': instrument_vector,\n",
    "                            'instruments': transformed_instruments\n",
    "                        }\n",
    "                        output_file_path = os.path.join(output_mood_path, json_file)\n",
    "                        with open(output_file_path, 'w') as out_file:\n",
    "                            json.dump(transformed_data, out_file, indent=4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_path = './2_output_features'\n",
    "    vocab_output_folder = './3_processed_features/instrument_vocabs'\n",
    "    processed_folder = './3_processed_features/data'\n",
    "    instrument_vocab_path = './3_processed_features/instrument_vocab.json'\n",
    "    \n",
    "    # Load the data and build the vocabulary\n",
    "    instrument_vocab = load_instrument_specific_vocab(dataset_path)\n",
    "    instru_vocab = load_instrument_vocab(instrument_vocab_path)\n",
    "    save_vocab(instrument_vocab, vocab_output_folder)\n",
    "    vocabs = load_all_vocabs(vocab_output_folder)\n",
    "    \n",
    "    # Transform the dataset using the loaded vocabularies\n",
    "    transform_dataset(dataset_path, vocabs, instru_vocab, processed_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "data_path = './3_processed_features/data'\n",
    "\n",
    "def load_data(data_path):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    mood_labels = {'angry': 0, 'happy': 1, 'relaxed': 2, 'sad': 3}\n",
    "    \n",
    "    for mood in os.listdir(data_path):\n",
    "        mood_path = os.path.join(data_path, mood)\n",
    "        for file in os.listdir(mood_path):\n",
    "            file_path = os.path.join(mood_path, file)\n",
    "            with open(file_path, 'r') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                for instrument, events in data['instruments'].items():\n",
    "                    if events:  # ensure there are events\n",
    "                        sequences.append(events)\n",
    "                        labels.append(mood_labels[mood])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    sequences = pad_sequences(sequences, padding='post')\n",
    "    labels = np.array(labels)\n",
    "    return sequences, labels\n",
    "\n",
    "sequences, labels = load_data(data_path)\n",
    "print(\"Loaded sequences:\", sequences.shape)\n",
    "print(\"Loaded labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "vocab_directory = './3_processed_features/instrument_vocabs'\n",
    "max_vocab_id = 0\n",
    "\n",
    "# Iterate through each vocab file and find the highest id\n",
    "for filename in os.listdir(vocab_directory):\n",
    "    filepath = os.path.join(vocab_directory, filename)\n",
    "    with open(filepath, 'r') as file:\n",
    "        vocab = json.load(file)\n",
    "        max_id = max(map(int, vocab.values()))  # Convert values to integers and find the max\n",
    "        max_vocab_id = max(max_vocab_id, max_id)\n",
    "\n",
    "# Since vocab indices are typically 0-based, add 1 to get the correct size\n",
    "max_vocab_size = max_vocab_id + 1\n",
    "\n",
    "print(\"The maximum vocabulary size is:\", max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = max_vocab_size \n",
    "embedding_dim = 64\n",
    "lstm_units = 128\n",
    "num_classes = 4  # Number of mood categories\n",
    "dropout_rate = 0.4\n",
    "\n",
    "# Define the model\n",
    "def build_model(vocab_size, embedding_dim, lstm_units, num_classes, dropout_rate):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True),\n",
    "        LSTM(lstm_units, return_sequences=True),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(lstm_units),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, lstm_units, num_classes, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model_dir = './trained_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Callbacks for monitoring and improving training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(model_dir, 'model_epoch{epoch:02d}_loss{val_loss:.2f}.keras'), \n",
    "    save_best_only=False, \n",
    "    monitor='val_loss', \n",
    "    mode='min', \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    sequences, labels,\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,  # Use 20% of the data for validation\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
